---
cluster_name: hadoop-poc
deploy_hadoop: true  ## Trigger 'Cluster Creation' in Ambari Server
hdp_version: '2.4'
java_type: oracle
custom_repo: false
custom_repo_url: ''
custom_repo_target: 'api/v1/stacks/HDP/versions/2.4/operating_systems/redhat6/repositories/HDP-2.4'
ambari_repo_host: public-repo-1.hortonworks.com
#ambari_repo_host: dev.hortonworks.com.s3.amazonaws.com
ambari_version: '2.2.2.0'
install_spark: true
install_ams: true
install_oozie: true
install_flume: true
install_hbase: false
install_storm: true
install_slider: true
install_kafka: true
install_falcon: true
tech_preview: false
install_zeppelin: false
install_nifi: false
install_solr: false
tachyon_service: false
blueprint_name: 'cluster_blueprint'
custom_blueprint: false
ambari_blueprint_recommendation_strategy: 'ONLY_STACK_DEFAULTS_APPLY'
admin_password: 'admin'
services_password: 'AsdQwe123'
alerts_contact: 'root@localhost.localdomain'
data_disks_filesystem: xfs
configure_firewall: false
update_etc_hosts: true

spark_stack: false
spark_stack_config:
  tachyon_worker_memory: '1GB'
  spark_exector_memory: '1g'
  spark_driver_memory: '1g'
  spark_driver_maxResultSize: '512M'
  zeppelin_spark_executor_memory: '1g'
  zeppelin_spark_cores_max: '1'
  default_user: 'dgrier'

hdfs:
  dfs_replication: 3
  failed_volumes_tolerated: 1
  ha_namenode: true

cloud_config:
  rax_credentials_file: '~/.raxpub'
  rax_region: 'ORD'

  domain: 'localnet'
  allowed_external_ips: ['127.0.0.1']
  ssh:
    keyname: 'hadoop-ssh-key'
    keyfile: '~/.ssh/id_rsa.pub'

# set to true to show host variables
debug: false

## for Hortonworks fork
install_smartsense: true
smartsense_customer_id: A-00000000-C-00000000
smartsense_customer_name: 'Hortonworks Data Platform AWS Marketplace'
smartsense_customer_email: 'aws-marketplace@hortonworks.com'

